# Homework Quiz

## Question 1
*I want to predict how well 6 year-olds are going to do in their final school exams. Using the following variables am I likely under-fitting, fitting well or over-fitting? Postcode, gender, reading level, score in maths test, date of birth, family income.*

## Question 2
*If I have two models, one with an AIC score of 34,902 and the other with an AIC score of 33,559 which model should I use?*

## Question 3
*I have two models, the first with: r-squared: 0.44, adjusted r-squared: 0.43. The second with: r-squared: 0.47, adjusted r-squared: 0.41. Which one should I use?*

## Question 4
*I have a model with the following errors: RMSE error on test set: 10.3, RMSE error on training data: 10.4. Do you think this model is over-fitting?*

## Question 5
*How does k-fold validation work?*

## Question 6
*What is a validation set? When do you need one?*

## Question 7
*Describe how backwards selection works.*

## Question 8
*Describe how best subset selection works.*

## Question 9
*It is estimated on 5% of model projects end up being deployed. What actions can you take to maximise the likelihood of your model being deployed?*

## Question 10
*What metric could you use to confirm that the recent population is similar to the development population?*

## Question 11
*How is the Population Stability Index defined? What does this mean in words?*

## Question 12
*Above what PSI value might we need to start to consider rebuilding or recalibrating the model*

## Question 13
*What are the common errors that can crop up when implementing a model?*

## Question 14
*After performance monitoring, if we find that the discrimination is still satisfactory but the accuracy has deteriorated, what is the recommended action?*

## Question 15
*Why is it important to have a unique model identifier for each model?*

## Question 16
*Why is it important to document the modelling rationale and approach?*
